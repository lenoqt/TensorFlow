{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d7597a-4dc5-4f6f-801b-0ddd97e878c4",
   "metadata": {},
   "source": [
    "Import tensorflow and MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b442cc-b429-46c5-a90a-bfa0b03bdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523ef574-770b-40b8-95c1-92f398bb09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channel dimension\n",
    "\n",
    "x_train = x_train[..., tf.newaxis].astype('float32')\n",
    "x_test = x_test[..., tf.newaxis].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a384b2b-0a3e-4534-bd92-4ff075d25456",
   "metadata": {},
   "source": [
    "Use ```tf.data``` to batch and shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4017d8-7eec-4b4b-b73b-ea61d07b7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 13:23:36.543811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-07-13 13:23:36.543855: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-07-13 13:23:36.543873: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (leno-lab): /proc/driver/nvidia/version does not exist\n",
      "2021-07-13 13:23:36.544097: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303ed1d-85f8-4ef4-a4aa-61c3321c72d5",
   "metadata": {},
   "source": [
    "Build the ```tf.keras``` model using the Keras model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be84ea08-3f8d-4c9b-8b2f-d8969ed3f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "    \n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c066ee3-2d25-40fb-b25e-9ac0dd3f0f89",
   "metadata": {},
   "source": [
    "Choose an optimizer and loss function for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d70b5e-933c-4ad8-8e5d-6eb07845c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0869511-874e-4ff3-ae01-af2e53de5137",
   "metadata": {},
   "source": [
    "Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c87e83-341f-4cc5-9633-1326533671b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f40b6-2b85-4880-8711-02ce9e07b191",
   "metadata": {},
   "source": [
    "Use ```tf.GradientTape``` to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7afdc21-3aab-42ce-b968-347cb2e7b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout)\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b8e57b-6220-45ff-a88c-39093986819b",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e31f24-154e-4719-8ec8-6ac0b1ee3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout)\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b461c190-555e-41a9-88d3-ec74330ce090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 13:42:22.593724: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-13 13:42:22.595201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3193550000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13439399003982544, Accuracy: 95.913330078125 Test Loss: 0.13151158392429352, Test Accuracy: 96.875\n",
      "Epoch 2, Loss: 0.041554976254701614, Accuracy: 98.69833374023438 Test Loss: 0.07082556933164597, Test Accuracy: 96.875\n",
      "Epoch 3, Loss: 0.02279694564640522, Accuracy: 99.27999877929688 Test Loss: 0.003552185371518135, Test Accuracy: 100.0\n",
      "Epoch 4, Loss: 0.013835900463163853, Accuracy: 99.57666015625 Test Loss: 0.0004788026271853596, Test Accuracy: 100.0\n",
      "Epoch 5, Loss: 0.008501800708472729, Accuracy: 99.69666290283203 Test Loss: 0.0008742220816202462, Test Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "    \n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(images, labels)\n",
    "        \n",
    "    print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100} '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74f098-46ba-4cad-af1c-7cb5bb73f9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
